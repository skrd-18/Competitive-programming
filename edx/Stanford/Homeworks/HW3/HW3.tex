%CS 109 Problem Set Template

\title{CS109 PSET Template}
\documentclass{article}
	% basic article document class
	% use percent signs to make comments to yourself -- they will not show up.
\usepackage{amsmath}
\usepackage{amssymb}
	% packages that allow mathematical formatting
\usepackage{graphicx}
	% package that allows you to include graphics
    %includegraphic[width=\textwidth]{FILENAME}
\usepackage[top=1in, bottom=1in, left=1in, right=1in]{geometry}
\frenchspacing
	% one space after periods
\usepackage{fancyhdr}
	% allows custom headers
\usepackage{relsize}
\pagestyle{fancy}
\setlength{\headheight}{24pt}% ...at least 23.1004pt
\lhead{edX, Stanford University \\ Problem Set 3} 
\rhead{Shiva}
\cfoot{\thepage}
\renewcommand{\footrulewidth}{0.4pt} 
	%footer

\begin{document}
\thispagestyle{fancy} %shows header/footer


\section*{Question 1: Minimum Cuts in a Tree}

\textbf{Problem:} How many different minimum cuts are there in a tree with $n$ nodes (i.e., $n-1$ edges)?

\textbf{Solution:}
A tree is defined as a connected acyclic graph. A tree with $n$ nodes has exactly $n-1$ edges.
\begin{enumerate}
	\item \textbf{Min-Cut Size:} By definition, removing any single edge from a tree disconnects the graph into exactly two connected components. Therefore, every edge defines a cut of size 1. Since a connected graph cannot have a cut of size 0, the minimum cut size is exactly 1.
	\item \textbf{Distinctness:} Each of the $n-1$ edges connects a unique pair of subtrees. Removing edge $e_i$ creates a partition $(A_i, B_i)$ that is distinct from the partition created by removing any other edge $e_j$.
	\item \textbf{Counting:} Since every edge corresponds to a distinct minimum cut, and there are $n-1$ edges, there are exactly $n-1$ minimum cuts.
\end{enumerate}

\[
	\text{Total Min Cuts} = \text{Number of Edges} = n - 1
\]

\textbf{Answer:} $n - 1$

\hrulefill

\section*{Question 2: Probability in Karger's Algorithm}

\textbf{Problem:} Let $p = \frac{1}{\binom{n}{2}}$. Analyze the probability $Pr[\text{out} = (A, B)]$ relative to $p$.

\textbf{Solution:}
The fundamental analysis of Karger's Random Contraction Algorithm provides a lower bound for the success probability.
Let $k$ be the size of the minimum cut. Since the min-cut is $k$, the degree of every vertex is at least $k$, meaning the graph has at least $nk/2$ edges.
The probability that a specific minimum cut $(A, B)$ survives the contraction process is:
\[
	Pr[\text{out} = (A, B)] \ge \frac{2}{n(n-1)} = \frac{1}{\binom{n}{2}} = p
\]
This inequality holds for \textbf{every} minimum cut in \textbf{every} graph.

Therefore, the correct statement is:
``For every graph $G$ with $n$ nodes and every min cut $(A, B)$ of $G$, $Pr[\text{out} = (A, B)] \ge p$.''

\hrulefill

\section*{Question 3: Randomized Selection Probability}

\textbf{Problem:} What is the probability that after one iteration of Randomized Select, the subarray size is $\le \alpha n$ (where $0.5 < \alpha < 1$)?

\textbf{Solution:}
Let the sorted elements of the array be $z_1, z_2, \dots, z_n$.
The algorithm picks a pivot $p$ uniformly at random.
To ensure the remaining subarray has size at most $\alpha n$, the pivot must partition the array such that neither the left side nor the right side is larger than $\alpha n$.
This occurs if the pivot falls in the "middle" of the sorted sequence.
\begin{itemize}
	\item \textbf{Bad Pivot (Left):} If $p$ is among the smallest $(1-\alpha)n$ elements, the right partition will be larger than $\alpha n$.
	\item \textbf{Bad Pivot (Right):} If $p$ is among the largest $(1-\alpha)n$ elements, the left partition will be larger than $\alpha n$.
\end{itemize}
The "Good Pivot" range is the indices between $(1-\alpha)n$ and $\alpha n$.
\[
	\text{Size of Good Range} = \alpha n - (1 - \alpha)n = (2\alpha - 1)n
\]
Since the pivot is chosen uniformly from $n$ elements:
\[
	Pr(\text{Good Pivot}) = \frac{(2\alpha - 1)n}{n} = 2\alpha - 1
\]

\textbf{Answer:} $2\alpha - 1$

\hrulefill

\section*{Question 4: Recursion Depth of RSelect}

\textbf{Problem:} If every recursive call reduces the input size to at most an $\alpha$ fraction ($0 < \alpha < 1$), what is the maximum recursion depth?

\textbf{Solution:}
Let $N_k$ be the input size at depth $k$. We are given the recurrence inequality:
\[
	N_k \le \alpha \cdot N_{k-1}
\]
Unrolling this from the initial size $n$:
\[
	N_k \le n \cdot \alpha^k
\]
The recursion terminates when the problem size reduces to 1 (base case).
\[
	1 = n \cdot \alpha^k
\]
Taking the logarithm of both sides:
\[
	\log(1) = \log(n \cdot \alpha^k)
\]
\[
	0 = \log(n) + k \log(\alpha)
\]
\[
	-k \log(\alpha) = \log(n)
\]
\[
	k = -\frac{\log(n)}{\log(\alpha)}
\]
(Note: Since $\alpha < 1$, $\log(\alpha)$ is negative, so the depth is positive).

\textbf{Answer:} $-\frac{\log n}{\log \alpha}$

\hrulefill

\section*{Question 5: Global Min Cut via s-t Min Cut}

\textbf{Problem:} Minimum number of calls to an s-t min cut subroutine needed to find the global min cut.

\textbf{Solution:}
The global minimum cut partitions the vertices $V$ into two disjoint sets, $S$ and $V \setminus S$.
\begin{enumerate}
	\item We fix an arbitrary vertex $s$. This vertex must belong to one of the two partitions (without loss of generality, assume $s \in S$).
	\item The other partition $V \setminus S$ is non-empty, so there exists at least one vertex $t \in V \setminus S$.
	\item We iterate through all possible candidate vertices for $t$ (all $v \in V, v \neq s$).
	\item By computing the Minimum $s-t$ Cut for every $t \in V \setminus \{s\}$, we are guaranteed that at least one iteration will have $t$ in the correct opposing set ($V \setminus S$).
	\item For that specific pair, the min $s-t$ cut will correspond exactly to the global min cut.
\end{enumerate}
Since we fix $s$ and iterate through all other nodes, the number of calls is $n-1$.

\textbf{Answer:} $n - 1$


\section*{Optional Problem 1: Lower Bound for Randomized Sorting}

\textbf{Problem:} Prove that the worst-case expected running time of every randomized comparison-based sorting algorithm is $\Omega(n \log n)$.

\textbf{Solution:}

To prove this, we utilize \textbf{Yao's Minimax Principle}, which allows us to establish a lower bound on the worst-case expected cost of a randomized algorithm by analyzing the average-case cost of a deterministic algorithm over a specific input distribution.

\begin{enumerate}
	\item \textbf{Definitions:}
	      \begin{itemize}
		      \item Let $\mathcal{A}$ be a randomized comparison-based sorting algorithm. We can view $\mathcal{A}$ as a probability distribution over a set of deterministic algorithms $\{D_1, D_2, \dots\}$.
		      \item Let $T(D, I)$ be the running time (number of comparisons) of deterministic algorithm $D$ on input $I$.
		      \item We are looking for the worst-case expected running time: $\max_{I} E[T(\mathcal{A}, I)]$.
	      \end{itemize}

	\item \textbf{Yao's Minimax Principle:}
	      Yao's principle states that for any probability distribution $\mathcal{P}$ over the set of inputs:
	      \[
		      \max_{I} E_{\mathcal{A}}[T(\mathcal{A}, I)] \geq \min_{D} E_{I \sim \mathcal{P}}[T(D, I)]
	      \]
	      In words: The worst-case expected time of the best randomized algorithm is at least the average-case time of the best deterministic algorithm for the "worst" input distribution.

	\item \textbf{Choosing the Input Distribution:}
	      Let $\mathcal{P}$ be the uniform distribution over all $n!$ possible permutations of the input array.

	\item \textbf{Deterministic Lower Bound:}
	      Consider any deterministic comparison-based sorting algorithm $D$. It can be modeled as a decision tree.
	      \begin{itemize}
		      \item The tree must have at least $n!$ leaves (one for each permutation) to correctly distinguish all inputs.
		      \item For a binary tree with $L$ leaves, the average depth (average path length from root to leaf) is lower bounded by $\Omega(\log L)$.
		      \item Substituting $L = n!$, the average depth is $\Omega(\log(n!))$.
		      \item Using Stirling's approximation ($\log(n!) = \Theta(n \log n)$), the average running time of any deterministic algorithm $D$ under the uniform distribution is $\Omega(n \log n)$.
	      \end{itemize}

	\item \textbf{Conclusion:}
	      Since $\min_{D} E_{I \sim \mathcal{P}}[T(D, I)] = \Omega(n \log n)$, by Yao's principle, the worst-case expected running time of any randomized algorithm is also $\Omega(n \log n)$.
\end{enumerate}

\hrulefill

\section*{Optional Problem 2: Deterministic Selection with Different Group Sizes}

\textbf{Problem:} Analyze the running time of the deterministic selection algorithm (Median-of-Medians) if we use group sizes of 7 and 3.

\subsection*{Part A: Group Size of 7}

Let $T(n)$ be the running time on an input of size $n$.
The algorithm steps are:
\begin{enumerate}
	\item Divide elements into $\lceil n/7 \rceil$ groups of 7. Find the median of each group. (Time: $O(n)$)
	\item Recursively find the median of these medians, call it $x$. (Time: $T(n/7)$)
	\item Partition the original array around $x$. (Time: $O(n)$)
	\item Recurse on the appropriate subarray. (Time: $T(k)$, where $k$ is the max subarray size)
\end{enumerate}

\textbf{Calculating the Recurrence:}
\begin{itemize}
	\item The number of groups is $\approx \frac{n}{7}$.
	\item The pivot $x$ is the median of the $\frac{n}{7}$ group medians.
	\item Therefore, $x$ is greater than $\frac{1}{2} \cdot \frac{n}{7} = \frac{n}{14}$ group medians.
	\item In each of these $\frac{n}{14}$ groups, there are 4 elements (the median itself and 3 elements greater than it) that are definitely $\ge x$.
	\item Total elements guaranteed $\ge x$: $4 \times \frac{n}{14} = \frac{2n}{7}$.
	\item Similarly, total elements guaranteed $\le x$: $\frac{2n}{7}$.
	\item In the worst case, the algorithm recurses on the remaining elements: $n - \frac{2n}{7} = \frac{5n}{7}$.
\end{itemize}

The recurrence is:
\[
	T(n) \le T\left(\frac{n}{7}\right) + T\left(\frac{5n}{7}\right) + O(n)
\]
We check if the sum of fractions is less than 1:
\[
	\frac{1}{7} + \frac{5}{7} = \frac{6}{7} < 1
\]
Since the sum is strictly less than 1, the running time is \textbf{linear}, i.e., $O(n)$.

\subsection*{Part B: Group Size of 3}

Using the same logic for groups of 3:
\begin{itemize}
	\item Number of groups: $\frac{n}{3}$.
	\item Pivot $x$ is greater than $\frac{1}{2} \cdot \frac{n}{3} = \frac{n}{6}$ medians.
	\item In each such group, there are 2 elements (median and 1 greater) definitely $\ge x$.
	\item Total elements guaranteed $\ge x$: $2 \times \frac{n}{6} = \frac{n}{3}$.
	\item Max elements in recursive step: $n - \frac{n}{3} = \frac{2n}{3}$.
\end{itemize}

The recurrence is:
\[
	T(n) \le T\left(\frac{n}{3}\right) + T\left(\frac{2n}{3}\right) + O(n)
\]
Sum of fractions:
\[
	\frac{1}{3} + \frac{2}{3} = 1
\]
Since the sum equals 1, this recurrence behaves like Merge Sort (specifically $T(n) = T(n/3) + T(2n/3) + cn$). The work per level is $O(n)$, and there are $\log n$ levels.
Thus, the running time is \textbf{$O(n \log n)$}, not linear.

\hrulefill

\section*{Optional Problem 3: Linear Time Weighted Median}

\textbf{Problem:} Compute all weighted medians in $O(n)$ worst-case time.

\textbf{Solution:}

We can adapt the standard deterministic selection algorithm. The key insight is that we can discard a portion of the array if we know the weighted median cannot be inside it, provided we account for the weights of the discarded elements.

\textbf{Algorithm:} \texttt{WeightedSelect(Array A, TargetWeight T)}
\begin{enumerate}
	\item \textbf{Base Case:} If $|A|$ is small (e.g., 1 or 2), solve by brute force.
	\item \textbf{Pivot Selection:} Use the deterministic Median-of-Medians algorithm to find the \textit{unweighted} median of $A$, call it $p$. This takes $O(|A|)$ time.
	\item \textbf{Partition:} Partition $A$ around $p$ into three sets:
	      \begin{itemize}
		      \item $L = \{x \in A \mid x < p\}$
		      \item $E = \{x \in A \mid x = p\}$
		      \item $G = \{x \in A \mid x > p\}$
	      \end{itemize}
	\item \textbf{Compute Weights:} Calculate the total weight of each set: $W_L = \sum_{x \in L} w_x$, $W_E = \sum_{x \in E} w_x$, $W_G = \sum_{x \in G} w_x$.
	\item \textbf{Recurse:}
	      \begin{itemize}
		      \item \textbf{Case 1:} If $W_L > T$, the weighted median must be in $L$.
		            \\ \textbf{Recurse:} \texttt{WeightedSelect(L, T)}
		      \item \textbf{Case 2:} If $W_L + W_E \ge T$, then $p$ is the weighted median (or one of them).
		            \\ \textbf{Return} $p$.
		      \item \textbf{Case 3:} If $W_L + W_E < T$, the weighted median is in $G$. However, we effectively "removed" $W_L + W_E$ weight from the left. We must adjust the target.
		            \\ \textbf{Recurse:} \texttt{WeightedSelect(G, $T - (W_L + W_E)$)}
	      \end{itemize}
\end{enumerate}

\textbf{Complexity Analysis:}
Since we use the median-of-medians as the pivot $p$, we guarantee that $|L| \le \frac{7}{10}n$ and $|G| \le \frac{7}{10}n$ (approx).
The recurrence is:
\[
	T(n) \le T(0.7n) + O(n)
\]
This geometric series sums to $O(n)$. Thus, the algorithm runs in \textbf{O(n)} worst-case time. To handle the initial call, we set $T = W_{total}/2$.

\hrulefill

\section*{Optional Problem 4: Minimum Cuts in Directed Graphs}

\textbf{Problem:} Is it true that every directed graph has only polynomially different minimum cuts? Prove it or give a counterexample.

\textbf{Solution:}

\textbf{No}, this is not true for directed graphs. A directed graph can have exponentially many global minimum cuts.

\textbf{Counterexample:}
Consider a simple directed graph $G$ with $n = k+2$ vertices: a source $s$, a sink $t$, and $k$ intermediate nodes $v_1, v_2, \dots, v_k$.
\begin{itemize}
	\item Add edges $s \to v_i$ with capacity 1 for all $i = 1 \dots k$.
	\item Add edges $v_i \to t$ with capacity 1 for all $i = 1 \dots k$.
	\item Add a back-edge $t \to s$ with capacity $\infty$.
\end{itemize}

\textbf{Analysis:}
\begin{enumerate}
	\item A global minimum cut partitions vertices into $(S, \bar{S})$.
	\item Due to the infinite edge $t \to s$, we cannot choose a cut where $t \in S$ and $s \in \bar{S}$.
	\item Thus, valid finite cuts must have $s \in S$ and $t \in \bar{S}$.
	\item For every intermediate node $v_i$, we have a choice:
	      \begin{itemize}
		      \item Put $v_i \in S$: The edge $v_i \to t$ is cut (cost 1).
		      \item Put $v_i \in \bar{S}$: The edge $s \to v_i$ is cut (cost 1).
	      \end{itemize}
	\item Regardless of the choice for each $v_i$, the cut size is exactly $1 \times k = k$.
	\item Since there are $k$ intermediate nodes and 2 choices for each, there are $2^k$ distinct cuts of size $k$.
	\item Since $k = n-2$, the number of minimum cuts is $2^{n-2}$, which is \textbf{exponential} in $n$.
\end{enumerate}

\hrulefill

\section*{Optional Problem 5: Number of $\alpha$-Minimum Cuts}

\textbf{Problem:} How many $\alpha$-minimum cuts can an undirected graph have? Prove the best upper bound.

\textbf{Solution:}

The upper bound is \textbf{$O(n^{2\alpha})$}.

\textbf{Proof using Karger's Algorithm:}
Let $k$ be the size of the minimum cut. An $\alpha$-minimum cut has size at most $\alpha k$.
\begin{enumerate}
	\item In a graph with min-cut $k$, the minimum degree is at least $k$. Thus, the total number of edges $m \ge \frac{nk}{2}$.
	\item Consider a specific $\alpha$-minimum cut $C$ with size $|C| \le \alpha k$.
	\item In Karger's contraction algorithm, when the graph has $r$ vertices remaining, the probability of choosing an edge in $C$ to contract is:
	      \[
		      P(\text{edge in } C) = \frac{|C|}{\text{Edges remaining}} \le \frac{\alpha k}{r k / 2} = \frac{2\alpha}{r}
	      \]
	\item The probability that $C$ survives this step is $1 - \frac{2\alpha}{r}$.
	\item The algorithm stops contraction when $2\alpha$ vertices remain (generalized version). The probability that $C$ survives from $n$ vertices down to $2\alpha$ vertices is:
	      \[
		      P(\text{survive}) \ge \prod_{r=2\alpha+1}^{n} \left(1 - \frac{2\alpha}{r}\right)
	      \]
	\item This product approximates to:
	      \[
		      \approx \frac{\binom{2\alpha}{2\alpha}}{\binom{n}{2\alpha}} = \frac{1}{\binom{n}{2\alpha}} \approx n^{-2\alpha}
	      \]
	\item Since each run of the algorithm produces the specific cut $C$ with probability at least $n^{-2\alpha}$, and the events for different cuts are disjoint in a single run output, the maximum number of such cuts is the reciprocal of the probability.
\end{enumerate}

\textbf{Result:} There are at most $O(n^{2\alpha})$ cuts of size $\alpha \times \text{min-cut}$.

\end{document}
